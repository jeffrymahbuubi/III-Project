{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PyTorch Implementation",
   "id": "90238db4fdbaa785"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "6adaecb3b48c6c00"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T07:50:42.738658Z",
     "start_time": "2024-11-26T07:50:42.708494Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Utility Functions\n",
   "id": "1314ab923857a68b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:12:50.192417Z",
     "start_time": "2024-11-26T08:12:50.146728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_path(indices):\n",
    "    if indices < 0 or indices >= len(model_name):\n",
    "        raise ValueError(\"Index out of range.\")\n",
    "    model_folder = Path(MODEL_DIR) / model_name[indices]\n",
    "    pth_files = glob.glob(str(model_folder / model_suffix))\n",
    "    \n",
    "    print(f\"Loaded Model from {pth_files[0]}\")\n",
    "    if not pth_files:\n",
    "        raise FileNotFoundError(f\"No '.pth' files found in {model_folder}.\")\n",
    "    return pth_files[0]  # Return the first matching `.pth` file\n",
    "\n",
    "def get_data(data_dir, batch_size=8, test_size=0.2, num_workers=0, random_state=42):\n",
    "    # Define transforms for the images\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
    "        transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "    ])\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = SignalDataset2D(data_dir=data_dir, transforms=data_transforms)\n",
    "    \n",
    "    # Create indices for train-test split\n",
    "    indices = list(range(len(dataset)))\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        indices, test_size=test_size, random_state=random_state, stratify=dataset.labels\n",
    "    )\n",
    "    \n",
    "    # Create subsets for train and validation\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # Create DataLoader objects\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "    \n",
    "def get_data_kfold(data_dir, batch_size=8, num_workers=0, num_folds=5, fold_index=0, random_state=42):\n",
    "    # Define transforms for the images\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
    "        transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "    ])\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = SignalDataset2D(data_dir=data_dir, transforms=data_transforms)\n",
    "    \n",
    "    # Prepare the labels for stratification\n",
    "    labels = dataset.labels\n",
    "    \n",
    "    # Set up StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Get the train/val indices for the chosen fold\n",
    "    all_splits = list(skf.split(range(len(dataset)), labels))\n",
    "    \n",
    "    if fold_index < 0 or fold_index >= num_folds:\n",
    "        raise ValueError(f\"Invalid fold_index {fold_index}. Must be between 0 and {num_folds - 1}.\")\n",
    "    \n",
    "    train_indices, val_indices = all_splits[fold_index]\n",
    "    \n",
    "    # Create subsets for train and validation\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # Create DataLoader objects\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def predict(model: torch.nn.Module, dataloader: DataLoader, device: torch.device, num_classes: int = 8):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    total_inference_time = 0  # To track total inference time\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            # Start the timer for inference\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Move data and labels to the device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Stop the timer after inference\n",
    "            end_time = time.time()\n",
    "            total_inference_time += (end_time - start_time)\n",
    "            \n",
    "            # Assuming the model's output is logits; apply softmax for class probabilities\n",
    "            probabilities = torch.softmax(output, dim=1)\n",
    "            predicted_labels = torch.argmax(probabilities, dim=1).cpu().numpy()\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_predictions.extend(predicted_labels)\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=list(range(num_classes)))\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    report = classification_report(all_labels, all_predictions, labels=list(range(num_classes)), output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Extract class-wise metrics\n",
    "    precision = {f\"class_{i}\": report[str(i)]['precision'] for i in range(num_classes)}\n",
    "    recall = {f\"class_{i}\": report[str(i)]['recall'] for i in range(num_classes)}\n",
    "    f1_score = {f\"class_{i}\": report[str(i)]['f1-score'] for i in range(num_classes)}\n",
    "    \n",
    "    # Compute mean metrics across classes\n",
    "    mean_precision = np.mean(list(precision.values()))\n",
    "    mean_recall = np.mean(list(recall.values()))\n",
    "    mean_f1 = np.mean(list(f1_score.values()))\n",
    "    \n",
    "    # Calculate inference speed\n",
    "    num_batches = len(dataloader)\n",
    "    avg_inference_time_per_batch = total_inference_time / num_batches if num_batches > 0 else 0\n",
    "    total_samples = len(all_labels)\n",
    "    avg_inference_time_per_sample = total_inference_time / total_samples if total_samples > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": all_predictions,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"mean_precision\": mean_precision,\n",
    "        \"mean_recall\": mean_recall,\n",
    "        \"mean_f1\": mean_f1,\n",
    "        \"conf_matrix\": conf_matrix,\n",
    "        \"class_precision\": precision,\n",
    "        \"class_recall\": recall,\n",
    "        \"class_f1\": f1_score,\n",
    "        \"labels\": all_labels,\n",
    "        \"total_inference_time\": total_inference_time,\n",
    "        \"avg_inference_time_per_batch\": avg_inference_time_per_batch,\n",
    "        \"avg_inference_time_per_sample\": avg_inference_time_per_sample\n",
    "    }"
   ],
   "id": "b943c83c1a119295",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Data Loading",
   "id": "1d137ba35bdd11cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T07:30:55.209320Z",
     "start_time": "2024-11-26T07:30:54.926142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SignalDataset2D(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transforms = transforms\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Verify the existence of class directories (0-7)\n",
    "        for class_label in range(8):  # Check for classes 0-7\n",
    "            class_dir = self.data_dir / str(class_label)\n",
    "            if not class_dir.exists() or not class_dir.is_dir():\n",
    "                raise FileNotFoundError(f\"Class directory '{class_label}' does not exist in {data_dir}.\")\n",
    "            \n",
    "            # Load all .png files for the class\n",
    "            class_files = list(class_dir.glob(\"*.png\"))\n",
    "            self.image_files.extend(class_files)\n",
    "            self.labels.extend([class_label] * len(class_files))\n",
    "        \n",
    "        if not self.image_files:\n",
    "            raise ValueError(f\"No images found in the dataset directory: {data_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_files[index]).convert(\"RGB\")\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Apply transforms if provided, otherwise return original image\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "\n",
    "DATA_DIR = Path(r'D:\\AUNUUN JEFFRY MAHBUUBI\\PROJECT AND RESEARCH\\PROJECTS\\35. Institute of Information\\CODE\\data')\n",
    "train_loader, val_loader = get_data(DATA_DIR, batch_size=8, test_size=0.2, num_workers=0, random_state=42)"
   ],
   "id": "1c31ae9c3e366289",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([8, 3, 224, 224]), Target shape: torch.Size([8])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Trained Model Loading",
   "id": "d38d3ff639d4ac17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T06:38:49.382071Z",
     "start_time": "2024-11-26T06:38:49.364926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_DIR = Path(r'D:\\AUNUUN JEFFRY MAHBUUBI\\PROJECT AND RESEARCH\\PROJECTS\\35. Institute of Information\\CODE\\model')\n",
    "\n",
    "model_name = ['PretrainAlexNet', 'PretrainAlexNetPruneL1', 'PretrainAlexNetPruneL2', \n",
    "              'PretrainMobileNetV2', 'PretrainMobileNetV2PruneL1', 'PretrainMobileNetV2PruneL2']\n",
    "\n",
    "model_suffix = '*.pth'\n",
    "\n",
    "model_path = get_model_path(0)\n",
    "print(f\"Model path: {model_path}\")"
   ],
   "id": "4009fb1bb50454e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: D:\\AUNUUN JEFFRY MAHBUUBI\\PROJECT AND RESEARCH\\PROJECTS\\35. Institute of Information\\CODE\\model\\PretrainAlexNet\\last_model_40.pth\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PyTorch Model Definition",
   "id": "3992a11d4aa49b47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T07:58:31.411181Z",
     "start_time": "2024-11-26T07:58:31.384253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PretrainedAlexNet2D(nn.Module):\n",
    "    def __init__(self, num_classes=8, pretrained=True):  # Change num_classes to match your dataset\n",
    "        super(PretrainedAlexNet2D, self).__init__()\n",
    "\n",
    "        # Load the pretrained AlexNet model\n",
    "        self.base_model = models.alexnet(pretrained=pretrained)\n",
    "\n",
    "        # Modify the classifier's final layer for custom output classes\n",
    "        if num_classes != 1000:  # ImageNet has 1000 classes\n",
    "            self.base_model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "class PretrainedAlexNet2DPrunedL1(nn.Module):\n",
    "    def __init__(self, num_classes=1000, pretrained=True, pruning_amount=0.2):\n",
    "        super(PretrainedAlexNet2DPrunedL1, self).__init__()\n",
    "\n",
    "        # Load the pretrained AlexNet model\n",
    "        self.base_model = models.alexnet(pretrained=pretrained)\n",
    "\n",
    "        # Modify the classifier's final layer for custom output classes\n",
    "        if num_classes != 1000:  # ImageNet has 1000 classes\n",
    "            self.base_model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "        # Apply L1 pruning to convolutional layers\n",
    "        for layer in self.base_model.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                prune.l1_unstructured(layer, name=\"weight\", amount=pruning_amount)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "class PretrainedAlexNet2DPrunedL2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, pretrained=True, pruning_amount=0.2):\n",
    "        super(PretrainedAlexNet2DPrunedL2, self).__init__()\n",
    "\n",
    "        # Load the pretrained AlexNet model\n",
    "        self.base_model = models.alexnet(pretrained=pretrained)\n",
    "\n",
    "        # Modify the classifier's final layer for custom output classes\n",
    "        if num_classes != 1000:  # ImageNet has 1000 classes\n",
    "            self.base_model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "        # Apply structured pruning (L2-norm) to convolutional layers\n",
    "        for layer in self.base_model.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                prune.ln_structured(layer, name=\"weight\", amount=pruning_amount, n=2, dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "class PretrainedMobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, pretrained=True):\n",
    "        super(PretrainedMobileNetV2, self).__init__()\n",
    "\n",
    "        # Load the pretrained MobileNetV2 model\n",
    "        self.base_model = models.mobilenet_v2(pretrained=pretrained)\n",
    "\n",
    "        # Modify the classifier's final layer for custom output classes\n",
    "        if num_classes != 1000:  # ImageNet has 1000 classes\n",
    "            self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "class PretrainedMobileNetV2WithL1Pruning(nn.Module):\n",
    "    def __init__(self, num_classes=1000, pretrained=True, pruning_amount=0.2):\n",
    "        super(PretrainedMobileNetV2WithL1Pruning, self).__init__()\n",
    "\n",
    "        # Load the pretrained MobileNetV2 model\n",
    "        self.base_model = models.mobilenet_v2(pretrained=pretrained)\n",
    "\n",
    "        # Modify the classifier's final layer for custom output classes\n",
    "        if num_classes != 1000:  # ImageNet has 1000 classes\n",
    "            self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Apply L1 pruning to the layers\n",
    "        for layer in self.base_model.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                prune.l1_unstructured(layer, name=\"weight\", amount=pruning_amount)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "class PretrainedMobileNetV2WithL2Pruning(nn.Module):\n",
    "    def __init__(self, num_classes=1000, pretrained=True, pruning_amount=0.2):\n",
    "        super(PretrainedMobileNetV2WithL2Pruning, self).__init__()\n",
    "\n",
    "        # Load the pretrained MobileNetV2 model\n",
    "        self.base_model = models.mobilenet_v2(pretrained=pretrained)\n",
    "\n",
    "        # Modify the classifier's final layer for custom output classes\n",
    "        if num_classes != 1000:  # ImageNet has 1000 classes\n",
    "            self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Apply L2 structured pruning to the layers\n",
    "        for layer in self.base_model.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                prune.ln_structured(layer, name=\"weight\", amount=pruning_amount, n=2, dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ],
   "id": "6053944e1791fecd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:16:24.757679Z",
     "start_time": "2024-11-26T08:16:23.077900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a mapping dictionary for models\n",
    "model_mapping = {\n",
    "    0: lambda: PretrainedAlexNet2D(num_classes=8),\n",
    "    1: lambda: PretrainedAlexNet2DPrunedL1(num_classes=8, pruning_amount=0.2),\n",
    "    2: lambda: PretrainedAlexNet2DPrunedL2(num_classes=8, pruning_amount=0.2),\n",
    "    3: lambda: PretrainedMobileNetV2(num_classes=8),\n",
    "    4: lambda: PretrainedMobileNetV2WithL1Pruning(num_classes=8, pruning_amount=0.2),\n",
    "    5: lambda: PretrainedMobileNetV2WithL2Pruning(num_classes=8, pruning_amount=0.2),\n",
    "}\n",
    "\n",
    "# Define the indices for the model\n",
    "indices = 3  # Change this to select the model dynamically\n",
    "\n",
    "# Ensure indices are valid\n",
    "if indices not in model_mapping:\n",
    "    raise ValueError(f\"Invalid index {indices}. Must be between 0 and {len(model_mapping) - 1}.\")\n",
    "\n",
    "# Initialize the model dynamically\n",
    "model = model_mapping[indices]()  # Use the lambda function to instantiate the model\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(get_model_path(indices))  # Replace get_model_path(indices) with the correct path to the .pth file\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load data\n",
    "# train_loader, val_loader = get_data(DATA_DIR, batch_size=8, test_size=0.2, num_workers=0, random_state=42)\n",
    "train_loader, val_loader = get_data_kfold(DATA_DIR, batch_size=8, num_workers=0, num_folds=5, fold_index=4, random_state=42)\n",
    "\n",
    "# Perform predictions\n",
    "results = predict(model, val_loader, device, num_classes=8)\n",
    "\n",
    "# Display overall results\n",
    "print(f\"Accuracy: {results['accuracy']:.2%}\")  # Display as a percentage\n",
    "print(f\"Mean Precision: {results['mean_precision']:.2%}\")\n",
    "print(f\"Mean Recall: {results['mean_recall']:.2%}\")\n",
    "print(f\"Mean F1: {results['mean_f1']:.2%}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(results['conf_matrix'])\n",
    "\n",
    "# Display metrics for each class\n",
    "print(\"\\nClass-wise Metrics:\")\n",
    "for cls in sorted(results['class_precision'].keys()):\n",
    "    precision = results['class_precision'][cls] * 100  # Convert to percentage\n",
    "    recall = results['class_recall'][cls] * 100\n",
    "    f1 = results['class_f1'][cls] * 100\n",
    "    print(f\"Class {cls}: Precision: {precision:.2f}%, Recall: {recall:.2f}%, F1-Score: {f1:.2f}%\")\n",
    "\n",
    "# Display inference time\n",
    "print(\"\\nInference Time:\")\n",
    "print(f\"Total Inference Time: {results['total_inference_time']:.4f} seconds\")\n",
    "print(f\"Average Inference Time per Batch: {results['avg_inference_time_per_batch']:.4f} seconds\")\n",
    "print(f\"Average Inference Time per Sample: {results['avg_inference_time_per_sample']:.6f} seconds\")\n",
    "\n"
   ],
   "id": "16b853fce4b9fafd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model from D:\\AUNUUN JEFFRY MAHBUUBI\\PROJECT AND RESEARCH\\PROJECTS\\35. Institute of Information\\CODE\\model\\PretrainMobileNetV2\\last_model_40.pth\n",
      "Accuracy: 66.25%\n",
      "Mean Precision: 69.34%\n",
      "Mean Recall: 66.25%\n",
      "Mean F1: 66.24%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9 0 0 0 1 0 0 0]\n",
      " [2 6 1 0 0 1 0 0]\n",
      " [0 0 5 2 1 1 1 0]\n",
      " [0 0 0 5 2 2 0 1]\n",
      " [0 0 0 2 7 1 0 0]\n",
      " [1 0 0 1 0 7 1 0]\n",
      " [0 0 0 0 0 4 5 1]\n",
      " [0 1 0 0 0 0 0 9]]\n",
      "\n",
      "Class-wise Metrics:\n",
      "Class class_0: Precision: 75.00%, Recall: 90.00%, F1-Score: 81.82%\n",
      "Class class_1: Precision: 85.71%, Recall: 60.00%, F1-Score: 70.59%\n",
      "Class class_2: Precision: 83.33%, Recall: 50.00%, F1-Score: 62.50%\n",
      "Class class_3: Precision: 50.00%, Recall: 50.00%, F1-Score: 50.00%\n",
      "Class class_4: Precision: 63.64%, Recall: 70.00%, F1-Score: 66.67%\n",
      "Class class_5: Precision: 43.75%, Recall: 70.00%, F1-Score: 53.85%\n",
      "Class class_6: Precision: 71.43%, Recall: 50.00%, F1-Score: 58.82%\n",
      "Class class_7: Precision: 81.82%, Recall: 90.00%, F1-Score: 85.71%\n",
      "\n",
      "Inference Time:\n",
      "Total Inference Time: 0.2764 seconds\n",
      "Average Inference Time per Batch: 0.0276 seconds\n",
      "Average Inference Time per Sample: 0.003455 seconds\n"
     ]
    }
   ],
   "execution_count": 78
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
